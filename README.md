# ðŸ‘‹ Hi, I'm Rahul! 

## ðŸš€ AWS | Data Engineer | PySpark | ETL | Big Data

ðŸŽ¯ I design, build, and automate cloud-based *data pipelines* to help transform raw data into actionable insights.

---

### ðŸ›  Tech Stack

- *Languages:* Python, SQL, PySpark
- *Cloud:* AWS (S3, Lambda, Glue, Athena, Redshift, CloudWatch)
- *Big Data:* Spark, Databricks, Parquet, Delta Lake
- *Workflow Orchestration:* Airflow, AWS EventBridge
- *Data Modeling & Querying:* AWS Glue Catalog, Athena, Redshift
- *Tools:* Git, VS Code, Postman, Jupyter

---

### ðŸ’¼ Projects

| Project | Description | Tech |
|--------|-------------|------|
| [Data Lakehouse for E-commerce Analytics](https://github.com/rtriders/Data-Lakehouse-for-E-commerce-Analytics) | Designed and implemented a scalable AWS-based Data Lakehouse on S3 with Glue and PySpark ETL, building partitioned pipelines and a star-schema warehouse in Redshift Spectrum to deliver near real-time analytics and actionable insights (e.g., top-selling products, high-value customers) that reduced reporting latency by 20% and enabled targeted marketing and sales strategies.  
| [Travel Recommendation ETL Pipeline](https://github.com/rtriders/Travel-Recommendation-ETL-Pipeline) | Built a Serverless pipeline using AWS Lambda, S3, Glue, and Athena to recommend travel cities based on weather data | AWS, Lambda, Athena, API, S3, Glue |
| [Google Books ETL Pipeline](https://github.com/rtriders/Google_books_data_pipeline) | Developed an automated ETL pipeline using Apache Airflow running in Docker containers, implemented data quality checks, and performed exploratory data analysis (EDA) on PostgreSQL to identify trends.| Airflow, Pandas, Postgres, Docker |

---

### ðŸ“š Currently Learning

- Advanced Airflow DAGs
- AWS Step Functions for ETL orchestration
- Data Lakehouse with Delta Lake

---

### ðŸ“« Connect With Me


 - [LinkedIn](https://www.linkedin.com/in/rahul-tewari-215515336)                       
 - [Portfolio Website](https://sites.google.com/view/rahultewari111/home)

 
